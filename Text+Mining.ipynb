{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deals with human language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLP Structure\n",
    "\n",
    "Chatbot -> NLP LAYER -> Knowledge Base(Source Content)\n",
    "\t\t\t\t\t->\tData Storage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application\n",
    "Spell Checking\n",
    "Keyword Searching\n",
    "Information Extractiong\n",
    "Advertisment matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Components of NLP\n",
    "Natural Language Understanding\n",
    "\tMapping Input to useful representation\n",
    "\tAnalysing different aspect of language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Natural language Generation\n",
    "\tText Planning\n",
    "\tSentence Planning\n",
    "\tText relization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLG\n",
    "\n",
    "\tLexical Ambiguity\n",
    "\t\tSame word with different meaning\n",
    "\t\t\tShe is looking for a matching\n",
    "\t\t\tFisherman went to the bank\n",
    "\t\t\n",
    "\tSyntatical Ambiguity\n",
    "\t\tTwo or more possible meaning in a sentence\n",
    "\t\t\tChicken is ready to eat\n",
    "\t\t\tI saw the man with binoculars\n",
    "\t\t\n",
    "\tReferencial Ambuguity\n",
    "\t\trefering to a thing with the pronoun - Who is HE?\n",
    "\t\t\tThe boy told his father the theft. HE was very upset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the library of NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batman = \"Batman is a fictional [superhero] appearing in American comic books published by DC Comics. The character was created by artist Bob Kane and writer Bill Finger,[1][2] and first appeared in Detective Comics #27, in 1939. Originally named the Bat-Man, the character is also referred to by such epithets as the Caped Crusader, the Dark Knight, and the World`s Greatest Detective.[5] Batman`s secret identity is Bruce Wayne, a wealthy American playboy, philanthropist, and owner of Wayne Enterprises. After witnessing the murder of his parents Dr. Thomas Wayne and Martha Wayne as a child, he swore vengeance against criminals, an oath tempered by a sense of justice. Bruce Wayne trains himself physically and intellectually and crafts a bat-inspired persona to fight crime.[6] Batman operates in the fictional Gotham City with assistance from various supporting characters, including his butler Alfred, police commissioner Gordon, and vigilante allies such as Robin. Unlike most superheroes, Batman does not possess any superpowers; rather, he relies on his genius intellect, physical prowess, martial arts abilities, detective skills, science and technology, vast wealth, intimidation, and indomitable will. A large assortment of villains make up Batman's rogues gallery, including his archenemy, the Joker. The character became popular soon after his introduction in 1939 and gained his own comic book title, Batman, the following year. As the decades went on, differing interpretations of the character emerged. The late 1960s Batman television series used a camp aesthetic, which continued to be associated with the character for years after the show ended. Various creators worked to return the character to his dark roots, culminating in 1986 with The Dark Knight Returns by Frank Miller. The success of Warner Bros. Pictures' live-action Batman feature films have helped maintain the character's prominence in mainstream culture.[7] An American cultural icon, Batman has garnered enormous popularity and is among the most identifiable comic book characters. Batman has been licensed and featured in various adaptations, from radio to television and film, and appears in merchandise sold around the world, such as apparel, toys, and video games. The character has also intrigued psychiatrists, with many offering interpretations of his psyche. In 2015, FanSided ranked Batman as number one on their list of 50 Greatest Super Heroes In Comic Book History.[8] Kevin Conroy, Rino Romano, Anthony Ruivivar, Peter Weller, Bruce Greenwood, Jason O'Mara, and Will Arnett, among others, have provided the character's voice for animated adaptations. Batman has been depicted in both film and television by Lewis Wilson, Robert Lowery, Adam West, Michael Keaton, Val Kilmer, George Clooney, Christian Bale, and Ben Affleck.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Tokenization\n",
    "\tProcess of breaking strings to tokens\n",
    "\t\tBreaking Complex sentence to words\n",
    "\t\timportance of words with each sentence\n",
    "\t\tProduce a structural desc on an input sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fictional',\n",
       " '[',\n",
       " 'superhero',\n",
       " ']',\n",
       " 'appearing',\n",
       " 'in',\n",
       " 'American',\n",
       " 'comic',\n",
       " 'books',\n",
       " 'published',\n",
       " 'by',\n",
       " 'DC',\n",
       " 'Comics',\n",
       " '.',\n",
       " 'The',\n",
       " 'character',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'artist',\n",
       " 'Bob',\n",
       " 'Kane',\n",
       " 'and',\n",
       " 'writer',\n",
       " 'Bill',\n",
       " 'Finger',\n",
       " ',',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'and',\n",
       " 'first',\n",
       " 'appeared',\n",
       " 'in',\n",
       " 'Detective',\n",
       " 'Comics',\n",
       " '#',\n",
       " '27',\n",
       " ',',\n",
       " 'in',\n",
       " '1939',\n",
       " '.',\n",
       " 'Originally',\n",
       " 'named',\n",
       " 'the',\n",
       " 'Bat-Man',\n",
       " ',',\n",
       " 'the',\n",
       " 'character',\n",
       " 'is',\n",
       " 'also',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'by',\n",
       " 'such',\n",
       " 'epithets',\n",
       " 'as',\n",
       " 'the',\n",
       " 'Caped',\n",
       " 'Crusader',\n",
       " ',',\n",
       " 'the',\n",
       " 'Dark',\n",
       " 'Knight',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'World',\n",
       " '`',\n",
       " 's',\n",
       " 'Greatest',\n",
       " 'Detective',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'Batman',\n",
       " '`',\n",
       " 's',\n",
       " 'secret',\n",
       " 'identity',\n",
       " 'is',\n",
       " 'Bruce',\n",
       " 'Wayne',\n",
       " ',',\n",
       " 'a',\n",
       " 'wealthy',\n",
       " 'American',\n",
       " 'playboy',\n",
       " ',',\n",
       " 'philanthropist',\n",
       " ',',\n",
       " 'and',\n",
       " 'owner',\n",
       " 'of',\n",
       " 'Wayne',\n",
       " 'Enterprises',\n",
       " '.',\n",
       " 'After',\n",
       " 'witnessing',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'of',\n",
       " 'his',\n",
       " 'parents',\n",
       " 'Dr.',\n",
       " 'Thomas',\n",
       " 'Wayne',\n",
       " 'and',\n",
       " 'Martha',\n",
       " 'Wayne',\n",
       " 'as',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'he',\n",
       " 'swore',\n",
       " 'vengeance',\n",
       " 'against',\n",
       " 'criminals',\n",
       " ',',\n",
       " 'an',\n",
       " 'oath',\n",
       " 'tempered',\n",
       " 'by',\n",
       " 'a',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'justice',\n",
       " '.',\n",
       " 'Bruce',\n",
       " 'Wayne',\n",
       " 'trains',\n",
       " 'himself',\n",
       " 'physically',\n",
       " 'and',\n",
       " 'intellectually',\n",
       " 'and',\n",
       " 'crafts',\n",
       " 'a',\n",
       " 'bat-inspired',\n",
       " 'persona',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'crime',\n",
       " '.',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'Batman',\n",
       " 'operates',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fictional',\n",
       " 'Gotham',\n",
       " 'City',\n",
       " 'with',\n",
       " 'assistance',\n",
       " 'from',\n",
       " 'various',\n",
       " 'supporting',\n",
       " 'characters',\n",
       " ',',\n",
       " 'including',\n",
       " 'his',\n",
       " 'butler',\n",
       " 'Alfred',\n",
       " ',',\n",
       " 'police',\n",
       " 'commissioner',\n",
       " 'Gordon',\n",
       " ',',\n",
       " 'and',\n",
       " 'vigilante',\n",
       " 'allies',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Robin',\n",
       " '.',\n",
       " 'Unlike',\n",
       " 'most',\n",
       " 'superheroes',\n",
       " ',',\n",
       " 'Batman',\n",
       " 'does',\n",
       " 'not',\n",
       " 'possess',\n",
       " 'any',\n",
       " 'superpowers',\n",
       " ';',\n",
       " 'rather',\n",
       " ',',\n",
       " 'he',\n",
       " 'relies',\n",
       " 'on',\n",
       " 'his',\n",
       " 'genius',\n",
       " 'intellect',\n",
       " ',',\n",
       " 'physical',\n",
       " 'prowess',\n",
       " ',',\n",
       " 'martial',\n",
       " 'arts',\n",
       " 'abilities',\n",
       " ',',\n",
       " 'detective',\n",
       " 'skills',\n",
       " ',',\n",
       " 'science',\n",
       " 'and',\n",
       " 'technology',\n",
       " ',',\n",
       " 'vast',\n",
       " 'wealth',\n",
       " ',',\n",
       " 'intimidation',\n",
       " ',',\n",
       " 'and',\n",
       " 'indomitable',\n",
       " 'will',\n",
       " '.',\n",
       " 'A',\n",
       " 'large',\n",
       " 'assortment',\n",
       " 'of',\n",
       " 'villains',\n",
       " 'make',\n",
       " 'up',\n",
       " 'Batman',\n",
       " \"'s\",\n",
       " 'rogues',\n",
       " 'gallery',\n",
       " ',',\n",
       " 'including',\n",
       " 'his',\n",
       " 'archenemy',\n",
       " ',',\n",
       " 'the',\n",
       " 'Joker',\n",
       " '.',\n",
       " 'The',\n",
       " 'character',\n",
       " 'became',\n",
       " 'popular',\n",
       " 'soon',\n",
       " 'after',\n",
       " 'his',\n",
       " 'introduction',\n",
       " 'in',\n",
       " '1939',\n",
       " 'and',\n",
       " 'gained',\n",
       " 'his',\n",
       " 'own',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'title',\n",
       " ',',\n",
       " 'Batman',\n",
       " ',',\n",
       " 'the',\n",
       " 'following',\n",
       " 'year',\n",
       " '.',\n",
       " 'As',\n",
       " 'the',\n",
       " 'decades',\n",
       " 'went',\n",
       " 'on',\n",
       " ',',\n",
       " 'differing',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'character',\n",
       " 'emerged',\n",
       " '.',\n",
       " 'The',\n",
       " 'late',\n",
       " '1960s',\n",
       " 'Batman',\n",
       " 'television',\n",
       " 'series',\n",
       " 'used',\n",
       " 'a',\n",
       " 'camp',\n",
       " 'aesthetic',\n",
       " ',',\n",
       " 'which',\n",
       " 'continued',\n",
       " 'to',\n",
       " 'be',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'the',\n",
       " 'character',\n",
       " 'for',\n",
       " 'years',\n",
       " 'after',\n",
       " 'the',\n",
       " 'show',\n",
       " 'ended',\n",
       " '.',\n",
       " 'Various',\n",
       " 'creators',\n",
       " 'worked',\n",
       " 'to',\n",
       " 'return',\n",
       " 'the',\n",
       " 'character',\n",
       " 'to',\n",
       " 'his',\n",
       " 'dark',\n",
       " 'roots',\n",
       " ',',\n",
       " 'culminating',\n",
       " 'in',\n",
       " '1986',\n",
       " 'with',\n",
       " 'The',\n",
       " 'Dark',\n",
       " 'Knight',\n",
       " 'Returns',\n",
       " 'by',\n",
       " 'Frank',\n",
       " 'Miller',\n",
       " '.',\n",
       " 'The',\n",
       " 'success',\n",
       " 'of',\n",
       " 'Warner',\n",
       " 'Bros.',\n",
       " 'Pictures',\n",
       " \"'\",\n",
       " 'live-action',\n",
       " 'Batman',\n",
       " 'feature',\n",
       " 'films',\n",
       " 'have',\n",
       " 'helped',\n",
       " 'maintain',\n",
       " 'the',\n",
       " 'character',\n",
       " \"'s\",\n",
       " 'prominence',\n",
       " 'in',\n",
       " 'mainstream',\n",
       " 'culture',\n",
       " '.',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'An',\n",
       " 'American',\n",
       " 'cultural',\n",
       " 'icon',\n",
       " ',',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'garnered',\n",
       " 'enormous',\n",
       " 'popularity',\n",
       " 'and',\n",
       " 'is',\n",
       " 'among',\n",
       " 'the',\n",
       " 'most',\n",
       " 'identifiable',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'characters',\n",
       " '.',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'been',\n",
       " 'licensed',\n",
       " 'and',\n",
       " 'featured',\n",
       " 'in',\n",
       " 'various',\n",
       " 'adaptations',\n",
       " ',',\n",
       " 'from',\n",
       " 'radio',\n",
       " 'to',\n",
       " 'television',\n",
       " 'and',\n",
       " 'film',\n",
       " ',',\n",
       " 'and',\n",
       " 'appears',\n",
       " 'in',\n",
       " 'merchandise',\n",
       " 'sold',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'apparel',\n",
       " ',',\n",
       " 'toys',\n",
       " ',',\n",
       " 'and',\n",
       " 'video',\n",
       " 'games',\n",
       " '.',\n",
       " 'The',\n",
       " 'character',\n",
       " 'has',\n",
       " 'also',\n",
       " 'intrigued',\n",
       " 'psychiatrists',\n",
       " ',',\n",
       " 'with',\n",
       " 'many',\n",
       " 'offering',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'his',\n",
       " 'psyche',\n",
       " '.',\n",
       " 'In',\n",
       " '2015',\n",
       " ',',\n",
       " 'FanSided',\n",
       " 'ranked',\n",
       " 'Batman',\n",
       " 'as',\n",
       " 'number',\n",
       " 'one',\n",
       " 'on',\n",
       " 'their',\n",
       " 'list',\n",
       " 'of',\n",
       " '50',\n",
       " 'Greatest',\n",
       " 'Super',\n",
       " 'Heroes',\n",
       " 'In',\n",
       " 'Comic',\n",
       " 'Book',\n",
       " 'History',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " 'Kevin',\n",
       " 'Conroy',\n",
       " ',',\n",
       " 'Rino',\n",
       " 'Romano',\n",
       " ',',\n",
       " 'Anthony',\n",
       " 'Ruivivar',\n",
       " ',',\n",
       " 'Peter',\n",
       " 'Weller',\n",
       " ',',\n",
       " 'Bruce',\n",
       " 'Greenwood',\n",
       " ',',\n",
       " 'Jason',\n",
       " \"O'Mara\",\n",
       " ',',\n",
       " 'and',\n",
       " 'Will',\n",
       " 'Arnett',\n",
       " ',',\n",
       " 'among',\n",
       " 'others',\n",
       " ',',\n",
       " 'have',\n",
       " 'provided',\n",
       " 'the',\n",
       " 'character',\n",
       " \"'s\",\n",
       " 'voice',\n",
       " 'for',\n",
       " 'animated',\n",
       " 'adaptations',\n",
       " '.',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'been',\n",
       " 'depicted',\n",
       " 'in',\n",
       " 'both',\n",
       " 'film',\n",
       " 'and',\n",
       " 'television',\n",
       " 'by',\n",
       " 'Lewis',\n",
       " 'Wilson',\n",
       " ',',\n",
       " 'Robert',\n",
       " 'Lowery',\n",
       " ',',\n",
       " 'Adam',\n",
       " 'West',\n",
       " ',',\n",
       " 'Michael',\n",
       " 'Keaton',\n",
       " ',',\n",
       " 'Val',\n",
       " 'Kilmer',\n",
       " ',',\n",
       " 'George',\n",
       " 'Clooney',\n",
       " ',',\n",
       " 'Christian',\n",
       " 'Bale',\n",
       " ',',\n",
       " 'and',\n",
       " 'Ben',\n",
       " 'Affleck',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bat_tokens = word_tokenize(batman)\n",
    "bat_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bat_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To find the no of occurence of the tokens or words in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 52, 'the': 24, '.': 20, 'and': 19, 'batman': 12, 'in': 12, 'character': 9, 'of': 8, 'his': 8, 'a': 7, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for words in bat_tokens:\n",
    "    fdist[words.lower()]+=1\n",
    "\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 52),\n",
       " ('the', 24),\n",
       " ('.', 20),\n",
       " ('and', 19),\n",
       " ('batman', 12),\n",
       " ('in', 12),\n",
       " ('character', 9),\n",
       " ('of', 8),\n",
       " ('his', 8),\n",
       " ('a', 7)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To find the blank lines in the para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "bat_blank = blankline_tokenize(batman)\n",
    "len(bat_blank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word gramming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ngrams - tokens of any no of written words\n",
    "bigram - tokens of 2 conscutive written words\n",
    "trigram - tokens of 3 consecutive written words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Edureka',\n",
       " 'video',\n",
       " 'will',\n",
       " 'provide',\n",
       " 'you',\n",
       " 'with',\n",
       " 'a',\n",
       " 'comprehensive',\n",
       " 'and',\n",
       " 'detailed',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " ',',\n",
       " 'popularly',\n",
       " 'known',\n",
       " 'as',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = \"This Edureka video will provide you with a comprehensive and detailed knowledge of Natural Language Processing, popularly known as NLP.\"\n",
    "\n",
    "quote_token = nltk.word_tokenize(strings)\n",
    "quote_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'Edureka'),\n",
       " ('Edureka', 'video'),\n",
       " ('video', 'will'),\n",
       " ('will', 'provide'),\n",
       " ('provide', 'you'),\n",
       " ('you', 'with'),\n",
       " ('with', 'a'),\n",
       " ('a', 'comprehensive'),\n",
       " ('comprehensive', 'and'),\n",
       " ('and', 'detailed'),\n",
       " ('detailed', 'knowledge'),\n",
       " ('knowledge', 'of'),\n",
       " ('of', 'Natural'),\n",
       " ('Natural', 'Language'),\n",
       " ('Language', 'Processing'),\n",
       " ('Processing', ','),\n",
       " (',', 'popularly'),\n",
       " ('popularly', 'known'),\n",
       " ('known', 'as'),\n",
       " ('as', 'NLP'),\n",
       " ('NLP', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_bigram = list(nltk.bigrams(quote_token))\n",
    "quote_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'Edureka', 'video'),\n",
       " ('Edureka', 'video', 'will'),\n",
       " ('video', 'will', 'provide'),\n",
       " ('will', 'provide', 'you'),\n",
       " ('provide', 'you', 'with'),\n",
       " ('you', 'with', 'a'),\n",
       " ('with', 'a', 'comprehensive'),\n",
       " ('a', 'comprehensive', 'and'),\n",
       " ('comprehensive', 'and', 'detailed'),\n",
       " ('and', 'detailed', 'knowledge'),\n",
       " ('detailed', 'knowledge', 'of'),\n",
       " ('knowledge', 'of', 'Natural'),\n",
       " ('of', 'Natural', 'Language'),\n",
       " ('Natural', 'Language', 'Processing'),\n",
       " ('Language', 'Processing', ','),\n",
       " ('Processing', ',', 'popularly'),\n",
       " (',', 'popularly', 'known'),\n",
       " ('popularly', 'known', 'as'),\n",
       " ('known', 'as', 'NLP'),\n",
       " ('as', 'NLP', '.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_trigram = list(nltk.trigrams(quote_token))\n",
    "quote_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'Edureka', 'video', 'will'),\n",
       " ('Edureka', 'video', 'will', 'provide'),\n",
       " ('video', 'will', 'provide', 'you'),\n",
       " ('will', 'provide', 'you', 'with'),\n",
       " ('provide', 'you', 'with', 'a'),\n",
       " ('you', 'with', 'a', 'comprehensive'),\n",
       " ('with', 'a', 'comprehensive', 'and'),\n",
       " ('a', 'comprehensive', 'and', 'detailed'),\n",
       " ('comprehensive', 'and', 'detailed', 'knowledge'),\n",
       " ('and', 'detailed', 'knowledge', 'of'),\n",
       " ('detailed', 'knowledge', 'of', 'Natural'),\n",
       " ('knowledge', 'of', 'Natural', 'Language'),\n",
       " ('of', 'Natural', 'Language', 'Processing'),\n",
       " ('Natural', 'Language', 'Processing', ','),\n",
       " ('Language', 'Processing', ',', 'popularly'),\n",
       " ('Processing', ',', 'popularly', 'known'),\n",
       " (',', 'popularly', 'known', 'as'),\n",
       " ('popularly', 'known', 'as', 'NLP'),\n",
       " ('known', 'as', 'NLP', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_ngram = list(nltk.ngrams(quote_token,4))\n",
    "quote_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ) Stemming\n",
    "\tNormalize words into its base form or root form\n",
    "\tto remove ing, er, ion ets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0980ec53aace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Having'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "pst.stem('Having')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_stem = [\"Give\", \"Given\", \"gave\", \"Giving\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-01c002a02784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords_stem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "for words in words_stem:\n",
    "    print(words + \":\" + pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stem() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8edf3c684f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords_stem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: stem() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "lst = LancasterStemmer\n",
    "\n",
    "for words in words_stem:\n",
    "    print(words + \":\" + lst.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### \n",
    "Groups together different infected forms of words called lemma\n",
    "Similar to stemming, as it maps into one common roots\n",
    "output of lemmatzation is one common word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\BLAZIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet, WordNetLemmatizer\n",
    "\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize(\"corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give:Give\n",
      "Given:Given\n",
      "gave:gave\n",
      "Giving:Giving\n"
     ]
    }
   ],
   "source": [
    "for words in words_stem:\n",
    "    print(words + \":\" + word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BLAZIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")\n",
    "len(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Punctuations\n",
    "import re\n",
    "punctuation = re.compile(r'[-.?!,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_punctuation = []\n",
    "\n",
    "for words in bat_tokens:\n",
    "    word = punctuation.sub(\"\", words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batman',\n",
       " 'is',\n",
       " 'a',\n",
       " 'fictional',\n",
       " '[',\n",
       " 'superhero',\n",
       " ']',\n",
       " 'appearing',\n",
       " 'in',\n",
       " 'American',\n",
       " 'comic',\n",
       " 'books',\n",
       " 'published',\n",
       " 'by',\n",
       " 'DC',\n",
       " 'Comics',\n",
       " 'The',\n",
       " 'character',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'artist',\n",
       " 'Bob',\n",
       " 'Kane',\n",
       " 'and',\n",
       " 'writer',\n",
       " 'Bill',\n",
       " 'Finger',\n",
       " '[',\n",
       " ']',\n",
       " '[',\n",
       " ']',\n",
       " 'and',\n",
       " 'first',\n",
       " 'appeared',\n",
       " 'in',\n",
       " 'Detective',\n",
       " 'Comics',\n",
       " '#',\n",
       " 'in',\n",
       " 'Originally',\n",
       " 'named',\n",
       " 'the',\n",
       " 'BatMan',\n",
       " 'the',\n",
       " 'character',\n",
       " 'is',\n",
       " 'also',\n",
       " 'referred',\n",
       " 'to',\n",
       " 'by',\n",
       " 'such',\n",
       " 'epithets',\n",
       " 'as',\n",
       " 'the',\n",
       " 'Caped',\n",
       " 'Crusader',\n",
       " 'the',\n",
       " 'Dark',\n",
       " 'Knight',\n",
       " 'and',\n",
       " 'the',\n",
       " 'World',\n",
       " '`',\n",
       " 's',\n",
       " 'Greatest',\n",
       " 'Detective',\n",
       " '[',\n",
       " ']',\n",
       " 'Batman',\n",
       " '`',\n",
       " 's',\n",
       " 'secret',\n",
       " 'identity',\n",
       " 'is',\n",
       " 'Bruce',\n",
       " 'Wayne',\n",
       " 'a',\n",
       " 'wealthy',\n",
       " 'American',\n",
       " 'playboy',\n",
       " 'philanthropist',\n",
       " 'and',\n",
       " 'owner',\n",
       " 'of',\n",
       " 'Wayne',\n",
       " 'Enterprises',\n",
       " 'After',\n",
       " 'witnessing',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'of',\n",
       " 'his',\n",
       " 'parents',\n",
       " 'Dr',\n",
       " 'Thomas',\n",
       " 'Wayne',\n",
       " 'and',\n",
       " 'Martha',\n",
       " 'Wayne',\n",
       " 'as',\n",
       " 'a',\n",
       " 'child',\n",
       " 'he',\n",
       " 'swore',\n",
       " 'vengeance',\n",
       " 'against',\n",
       " 'criminals',\n",
       " 'an',\n",
       " 'oath',\n",
       " 'tempered',\n",
       " 'by',\n",
       " 'a',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'justice',\n",
       " 'Bruce',\n",
       " 'Wayne',\n",
       " 'trains',\n",
       " 'himself',\n",
       " 'physically',\n",
       " 'and',\n",
       " 'intellectually',\n",
       " 'and',\n",
       " 'crafts',\n",
       " 'a',\n",
       " 'batinspired',\n",
       " 'persona',\n",
       " 'to',\n",
       " 'fight',\n",
       " 'crime',\n",
       " '[',\n",
       " ']',\n",
       " 'Batman',\n",
       " 'operates',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fictional',\n",
       " 'Gotham',\n",
       " 'City',\n",
       " 'with',\n",
       " 'assistance',\n",
       " 'from',\n",
       " 'various',\n",
       " 'supporting',\n",
       " 'characters',\n",
       " 'including',\n",
       " 'his',\n",
       " 'butler',\n",
       " 'Alfred',\n",
       " 'police',\n",
       " 'commissioner',\n",
       " 'Gordon',\n",
       " 'and',\n",
       " 'vigilante',\n",
       " 'allies',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Robin',\n",
       " 'Unlike',\n",
       " 'most',\n",
       " 'superheroes',\n",
       " 'Batman',\n",
       " 'does',\n",
       " 'not',\n",
       " 'possess',\n",
       " 'any',\n",
       " 'superpowers',\n",
       " 'rather',\n",
       " 'he',\n",
       " 'relies',\n",
       " 'on',\n",
       " 'his',\n",
       " 'genius',\n",
       " 'intellect',\n",
       " 'physical',\n",
       " 'prowess',\n",
       " 'martial',\n",
       " 'arts',\n",
       " 'abilities',\n",
       " 'detective',\n",
       " 'skills',\n",
       " 'science',\n",
       " 'and',\n",
       " 'technology',\n",
       " 'vast',\n",
       " 'wealth',\n",
       " 'intimidation',\n",
       " 'and',\n",
       " 'indomitable',\n",
       " 'will',\n",
       " 'A',\n",
       " 'large',\n",
       " 'assortment',\n",
       " 'of',\n",
       " 'villains',\n",
       " 'make',\n",
       " 'up',\n",
       " 'Batman',\n",
       " \"'s\",\n",
       " 'rogues',\n",
       " 'gallery',\n",
       " 'including',\n",
       " 'his',\n",
       " 'archenemy',\n",
       " 'the',\n",
       " 'Joker',\n",
       " 'The',\n",
       " 'character',\n",
       " 'became',\n",
       " 'popular',\n",
       " 'soon',\n",
       " 'after',\n",
       " 'his',\n",
       " 'introduction',\n",
       " 'in',\n",
       " 'and',\n",
       " 'gained',\n",
       " 'his',\n",
       " 'own',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'title',\n",
       " 'Batman',\n",
       " 'the',\n",
       " 'following',\n",
       " 'year',\n",
       " 'As',\n",
       " 'the',\n",
       " 'decades',\n",
       " 'went',\n",
       " 'on',\n",
       " 'differing',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'character',\n",
       " 'emerged',\n",
       " 'The',\n",
       " 'late',\n",
       " 's',\n",
       " 'Batman',\n",
       " 'television',\n",
       " 'series',\n",
       " 'used',\n",
       " 'a',\n",
       " 'camp',\n",
       " 'aesthetic',\n",
       " 'which',\n",
       " 'continued',\n",
       " 'to',\n",
       " 'be',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'the',\n",
       " 'character',\n",
       " 'for',\n",
       " 'years',\n",
       " 'after',\n",
       " 'the',\n",
       " 'show',\n",
       " 'ended',\n",
       " 'Various',\n",
       " 'creators',\n",
       " 'worked',\n",
       " 'to',\n",
       " 'return',\n",
       " 'the',\n",
       " 'character',\n",
       " 'to',\n",
       " 'his',\n",
       " 'dark',\n",
       " 'roots',\n",
       " 'culminating',\n",
       " 'in',\n",
       " 'with',\n",
       " 'The',\n",
       " 'Dark',\n",
       " 'Knight',\n",
       " 'Returns',\n",
       " 'by',\n",
       " 'Frank',\n",
       " 'Miller',\n",
       " 'The',\n",
       " 'success',\n",
       " 'of',\n",
       " 'Warner',\n",
       " 'Bros',\n",
       " 'Pictures',\n",
       " \"'\",\n",
       " 'liveaction',\n",
       " 'Batman',\n",
       " 'feature',\n",
       " 'films',\n",
       " 'have',\n",
       " 'helped',\n",
       " 'maintain',\n",
       " 'the',\n",
       " 'character',\n",
       " \"'s\",\n",
       " 'prominence',\n",
       " 'in',\n",
       " 'mainstream',\n",
       " 'culture',\n",
       " '[',\n",
       " ']',\n",
       " 'An',\n",
       " 'American',\n",
       " 'cultural',\n",
       " 'icon',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'garnered',\n",
       " 'enormous',\n",
       " 'popularity',\n",
       " 'and',\n",
       " 'is',\n",
       " 'among',\n",
       " 'the',\n",
       " 'most',\n",
       " 'identifiable',\n",
       " 'comic',\n",
       " 'book',\n",
       " 'characters',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'been',\n",
       " 'licensed',\n",
       " 'and',\n",
       " 'featured',\n",
       " 'in',\n",
       " 'various',\n",
       " 'adaptations',\n",
       " 'from',\n",
       " 'radio',\n",
       " 'to',\n",
       " 'television',\n",
       " 'and',\n",
       " 'film',\n",
       " 'and',\n",
       " 'appears',\n",
       " 'in',\n",
       " 'merchandise',\n",
       " 'sold',\n",
       " 'around',\n",
       " 'the',\n",
       " 'world',\n",
       " 'such',\n",
       " 'as',\n",
       " 'apparel',\n",
       " 'toys',\n",
       " 'and',\n",
       " 'video',\n",
       " 'games',\n",
       " 'The',\n",
       " 'character',\n",
       " 'has',\n",
       " 'also',\n",
       " 'intrigued',\n",
       " 'psychiatrists',\n",
       " 'with',\n",
       " 'many',\n",
       " 'offering',\n",
       " 'interpretations',\n",
       " 'of',\n",
       " 'his',\n",
       " 'psyche',\n",
       " 'In',\n",
       " 'FanSided',\n",
       " 'ranked',\n",
       " 'Batman',\n",
       " 'as',\n",
       " 'number',\n",
       " 'one',\n",
       " 'on',\n",
       " 'their',\n",
       " 'list',\n",
       " 'of',\n",
       " 'Greatest',\n",
       " 'Super',\n",
       " 'Heroes',\n",
       " 'In',\n",
       " 'Comic',\n",
       " 'Book',\n",
       " 'History',\n",
       " '[',\n",
       " ']',\n",
       " 'Kevin',\n",
       " 'Conroy',\n",
       " 'Rino',\n",
       " 'Romano',\n",
       " 'Anthony',\n",
       " 'Ruivivar',\n",
       " 'Peter',\n",
       " 'Weller',\n",
       " 'Bruce',\n",
       " 'Greenwood',\n",
       " 'Jason',\n",
       " \"O'Mara\",\n",
       " 'and',\n",
       " 'Will',\n",
       " 'Arnett',\n",
       " 'among',\n",
       " 'others',\n",
       " 'have',\n",
       " 'provided',\n",
       " 'the',\n",
       " 'character',\n",
       " \"'s\",\n",
       " 'voice',\n",
       " 'for',\n",
       " 'animated',\n",
       " 'adaptations',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'been',\n",
       " 'depicted',\n",
       " 'in',\n",
       " 'both',\n",
       " 'film',\n",
       " 'and',\n",
       " 'television',\n",
       " 'by',\n",
       " 'Lewis',\n",
       " 'Wilson',\n",
       " 'Robert',\n",
       " 'Lowery',\n",
       " 'Adam',\n",
       " 'West',\n",
       " 'Michael',\n",
       " 'Keaton',\n",
       " 'Val',\n",
       " 'Kilmer',\n",
       " 'George',\n",
       " 'Clooney',\n",
       " 'Christian',\n",
       " 'Bale',\n",
       " 'and',\n",
       " 'Ben',\n",
       " 'Affleck']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(post_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parts of speech to find the type of word in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\BLAZIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"The Joker is a fictional character who appears in Christopher Nolan's 2008 superhero film The Dark Knight. Based upon the DC Comics character of the same name, he was played by Australian actor Heath Ledger.\"\n",
    "sent_tokenize = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT')]\n",
      "[('Joker', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('fictional', 'JJ')]\n",
      "[('character', 'NN')]\n",
      "[('who', 'WP')]\n",
      "[('appears', 'VBZ')]\n",
      "[('in', 'IN')]\n",
      "[('Christopher', 'NN')]\n",
      "[('Nolan', 'NN')]\n",
      "[(\"'s\", 'POS')]\n",
      "[('2008', 'CD')]\n",
      "[('superhero', 'NN')]\n",
      "[('film', 'NN')]\n",
      "[('The', 'DT')]\n",
      "[('Dark', 'NN')]\n",
      "[('Knight', 'NNP')]\n",
      "[('.', '.')]\n",
      "[('Based', 'VBN')]\n",
      "[('upon', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('DC', 'NN')]\n",
      "[('Comics', 'NNS')]\n",
      "[('character', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('same', 'JJ')]\n",
      "[('name', 'NN')]\n",
      "[(',', ',')]\n",
      "[('he', 'PRP')]\n",
      "[('was', 'VBD')]\n",
      "[('played', 'NNS')]\n",
      "[('by', 'IN')]\n",
      "[('Australian', 'JJ')]\n",
      "[('actor', 'NN')]\n",
      "[('Heath', 'NN')]\n",
      "[('Ledger', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for tokens in sent_tokenize:\n",
    "    print(nltk.pos_tag([tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent2 = \"Mr. Freeze is a fictional supervillain appearing in American comic books published by DC Comics, commonly as an adversary of the superhero Batman. Created by writer Dave Wood and artist Sheldon Moldoff, the character first appeared in Batman #121, where he was known as Mr. Zero.\"\n",
    "sent2_tokenize = word_tokenize(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mr', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Freeze', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('fictional', 'JJ')]\n",
      "[('supervillain', 'NN')]\n",
      "[('appearing', 'VBG')]\n",
      "[('in', 'IN')]\n",
      "[('American', 'JJ')]\n",
      "[('comic', 'JJ')]\n",
      "[('books', 'NNS')]\n",
      "[('published', 'VBN')]\n",
      "[('by', 'IN')]\n",
      "[('DC', 'NN')]\n",
      "[('Comics', 'NNS')]\n",
      "[(',', ',')]\n",
      "[('commonly', 'RB')]\n",
      "[('as', 'IN')]\n",
      "[('an', 'DT')]\n",
      "[('adversary', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('the', 'DT')]\n",
      "[('superhero', 'NN')]\n",
      "[('Batman', 'NNP')]\n",
      "[('.', '.')]\n",
      "[('Created', 'VBN')]\n",
      "[('by', 'IN')]\n",
      "[('writer', 'NN')]\n",
      "[('Dave', 'VB')]\n",
      "[('Wood', 'NN')]\n",
      "[('and', 'CC')]\n",
      "[('artist', 'NN')]\n",
      "[('Sheldon', 'NN')]\n",
      "[('Moldoff', 'NN')]\n",
      "[(',', ',')]\n",
      "[('the', 'DT')]\n",
      "[('character', 'NN')]\n",
      "[('first', 'RB')]\n",
      "[('appeared', 'VBD')]\n",
      "[('in', 'IN')]\n",
      "[('Batman', 'NNP')]\n",
      "[('#', '#')]\n",
      "[('121', 'CD')]\n",
      "[(',', ',')]\n",
      "[('where', 'WRB')]\n",
      "[('he', 'PRP')]\n",
      "[('was', 'VBD')]\n",
      "[('known', 'VBN')]\n",
      "[('as', 'IN')]\n",
      "[('Mr', 'NN')]\n",
      "[('.', '.')]\n",
      "[('Zero', 'NN')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "for tokens in sent2_tokenize:\n",
    "    print(nltk.pos_tag([tokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition - \n",
    "to identify movie, location, names, monetary values, organization, quatities, person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\BLAZIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\BLAZIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NE_sent = \"The world is not enough in Russia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ne_tokenize = word_tokenize(NE_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NE_tags = nltk.pos_tag(Ne_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S The/DT world/NN is/VBZ not/RB enough/RB in/IN (GPE Russia/NNP))\n"
     ]
    }
   ],
   "source": [
    "NE_NER = ne_chunk(NE_tags)\n",
    "print(NE_NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Betty', 'NNP'),\n",
       " ('bought', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('bit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('butter', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('bit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('butter', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('bitter', 'JJ')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chunk = \"Betty bought a bit of butter but the bit of butter was bitter\"\n",
    "new_tokens = nltk.pos_tag(word_tokenize(new_chunk))\n",
    "\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammer_np = r\"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'RegexParser'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-bb532d5fa93d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchunk_parser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRegexParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrammer_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'RegexParser'"
     ]
    }
   ],
   "source": [
    "chunk_parser = nltk.RegexParser(grammer_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-4a346cc62edf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchunk_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchunk_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mchunk_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunk_parser' is not defined"
     ]
    }
   ],
   "source": [
    "chunk_result = chunk_parser.parse(new_tokens)\n",
    "chunk_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stopwords', 'stopwords.zip', 'wordnet', 'wordnet.zip', 'words', 'words.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\BLAZIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      " \n",
      "['pos/cv000_29590.txt', 'pos/cv001_18431.txt', 'pos/cv002_15918.txt', 'pos/cv003_11664.txt', 'pos/cv004_11636.txt', 'pos/cv005_29443.txt', 'pos/cv006_15448.txt', 'pos/cv007_4968.txt', 'pos/cv008_29435.txt', 'pos/cv009_29592.txt', 'pos/cv010_29198.txt', 'pos/cv011_12166.txt', 'pos/cv012_29576.txt', 'pos/cv013_10159.txt', 'pos/cv014_13924.txt', 'pos/cv015_29439.txt', 'pos/cv016_4659.txt', 'pos/cv017_22464.txt', 'pos/cv018_20137.txt', 'pos/cv019_14482.txt', 'pos/cv020_8825.txt', 'pos/cv021_15838.txt', 'pos/cv022_12864.txt', 'pos/cv023_12672.txt', 'pos/cv024_6778.txt', 'pos/cv025_3108.txt', 'pos/cv026_29325.txt', 'pos/cv027_25219.txt', 'pos/cv028_26746.txt', 'pos/cv029_18643.txt', 'pos/cv030_21593.txt', 'pos/cv031_18452.txt', 'pos/cv032_22550.txt', 'pos/cv033_24444.txt', 'pos/cv034_29647.txt', 'pos/cv035_3954.txt', 'pos/cv036_16831.txt', 'pos/cv037_18510.txt', 'pos/cv038_9749.txt', 'pos/cv039_6170.txt', 'pos/cv040_8276.txt', 'pos/cv041_21113.txt', 'pos/cv042_10982.txt', 'pos/cv043_15013.txt', 'pos/cv044_16969.txt', 'pos/cv045_23923.txt', 'pos/cv046_10188.txt', 'pos/cv047_1754.txt', 'pos/cv048_16828.txt', 'pos/cv049_20471.txt', 'pos/cv050_11175.txt', 'pos/cv051_10306.txt', 'pos/cv052_29378.txt', 'pos/cv053_21822.txt', 'pos/cv054_4230.txt', 'pos/cv055_8338.txt', 'pos/cv056_13133.txt', 'pos/cv057_7453.txt', 'pos/cv058_8025.txt', 'pos/cv059_28885.txt', 'pos/cv060_10844.txt', 'pos/cv061_8837.txt', 'pos/cv062_23115.txt', 'pos/cv063_28997.txt', 'pos/cv064_24576.txt', 'pos/cv065_15248.txt', 'pos/cv066_10821.txt', 'pos/cv067_19774.txt', 'pos/cv068_13400.txt', 'pos/cv069_10801.txt', 'pos/cv070_12289.txt', 'pos/cv071_12095.txt', 'pos/cv072_6169.txt', 'pos/cv073_21785.txt', 'pos/cv074_6875.txt', 'pos/cv075_6500.txt', 'pos/cv076_24945.txt', 'pos/cv077_22138.txt', 'pos/cv078_14730.txt', 'pos/cv079_11933.txt', 'pos/cv080_13465.txt', 'pos/cv081_16582.txt', 'pos/cv082_11080.txt', 'pos/cv083_24234.txt', 'pos/cv084_13566.txt', 'pos/cv085_1381.txt', 'pos/cv086_18371.txt', 'pos/cv087_1989.txt', 'pos/cv088_24113.txt', 'pos/cv089_11418.txt', 'pos/cv090_0042.txt', 'pos/cv091_7400.txt', 'pos/cv092_28017.txt', 'pos/cv093_13951.txt', 'pos/cv094_27889.txt', 'pos/cv095_28892.txt', 'pos/cv096_11474.txt', 'pos/cv097_24970.txt', 'pos/cv098_15435.txt', 'pos/cv099_10534.txt', 'pos/cv100_11528.txt', 'pos/cv101_10175.txt', 'pos/cv102_7846.txt', 'pos/cv103_11021.txt', 'pos/cv104_18134.txt', 'pos/cv105_17990.txt', 'pos/cv106_16807.txt', 'pos/cv107_24319.txt', 'pos/cv108_15571.txt', 'pos/cv109_21172.txt', 'pos/cv110_27788.txt', 'pos/cv111_11473.txt', 'pos/cv112_11193.txt', 'pos/cv113_23102.txt', 'pos/cv114_18398.txt', 'pos/cv115_25396.txt', 'pos/cv116_28942.txt', 'pos/cv117_24295.txt', 'pos/cv118_28980.txt', 'pos/cv119_9867.txt', 'pos/cv120_4111.txt', 'pos/cv121_17302.txt', 'pos/cv122_7392.txt', 'pos/cv123_11182.txt', 'pos/cv124_4122.txt', 'pos/cv125_9391.txt', 'pos/cv126_28971.txt', 'pos/cv127_14711.txt', 'pos/cv128_29627.txt', 'pos/cv129_16741.txt', 'pos/cv130_17083.txt', 'pos/cv131_10713.txt', 'pos/cv132_5618.txt', 'pos/cv133_16336.txt', 'pos/cv134_22246.txt', 'pos/cv135_11603.txt', 'pos/cv136_11505.txt', 'pos/cv137_15422.txt', 'pos/cv138_12721.txt', 'pos/cv139_12873.txt', 'pos/cv140_7479.txt', 'pos/cv141_15686.txt', 'pos/cv142_22516.txt', 'pos/cv143_19666.txt', 'pos/cv144_5007.txt', 'pos/cv145_11472.txt', 'pos/cv146_18458.txt', 'pos/cv147_21193.txt', 'pos/cv148_16345.txt', 'pos/cv149_15670.txt', 'pos/cv150_12916.txt', 'pos/cv151_15771.txt', 'pos/cv152_8736.txt', 'pos/cv153_10779.txt', 'pos/cv154_9328.txt', 'pos/cv155_7308.txt', 'pos/cv156_10481.txt', 'pos/cv157_29372.txt', 'pos/cv158_10390.txt', 'pos/cv159_29505.txt', 'pos/cv160_10362.txt', 'pos/cv161_11425.txt', 'pos/cv162_10424.txt', 'pos/cv163_10052.txt', 'pos/cv164_22447.txt', 'pos/cv165_22619.txt', 'pos/cv166_11052.txt', 'pos/cv167_16376.txt', 'pos/cv168_7050.txt', 'pos/cv169_23778.txt', 'pos/cv170_3006.txt', 'pos/cv171_13537.txt', 'pos/cv172_11131.txt', 'pos/cv173_4471.txt', 'pos/cv174_9659.txt', 'pos/cv175_6964.txt', 'pos/cv176_12857.txt', 'pos/cv177_10367.txt', 'pos/cv178_12972.txt', 'pos/cv179_9228.txt', 'pos/cv180_16113.txt', 'pos/cv181_14401.txt', 'pos/cv182_7281.txt', 'pos/cv183_18612.txt', 'pos/cv184_2673.txt', 'pos/cv185_28654.txt', 'pos/cv186_2269.txt', 'pos/cv187_12829.txt', 'pos/cv188_19226.txt', 'pos/cv189_22934.txt', 'pos/cv190_27052.txt', 'pos/cv191_29719.txt', 'pos/cv192_14395.txt', 'pos/cv193_5416.txt', 'pos/cv194_12079.txt', 'pos/cv195_14528.txt', 'pos/cv196_29027.txt', 'pos/cv197_29328.txt', 'pos/cv198_18180.txt', 'pos/cv199_9629.txt', 'pos/cv200_2915.txt', 'pos/cv201_6997.txt', 'pos/cv202_10654.txt', 'pos/cv203_17986.txt', 'pos/cv204_8451.txt', 'pos/cv205_9457.txt', 'pos/cv206_14293.txt', 'pos/cv207_29284.txt', 'pos/cv208_9020.txt', 'pos/cv209_29118.txt', 'pos/cv210_9312.txt', 'pos/cv211_9953.txt', 'pos/cv212_10027.txt', 'pos/cv213_18934.txt', 'pos/cv214_12294.txt', 'pos/cv215_22240.txt', 'pos/cv216_18738.txt', 'pos/cv217_28842.txt', 'pos/cv218_24352.txt', 'pos/cv219_18626.txt', 'pos/cv220_29059.txt', 'pos/cv221_2695.txt', 'pos/cv222_17395.txt', 'pos/cv223_29066.txt', 'pos/cv224_17661.txt', 'pos/cv225_29224.txt', 'pos/cv226_2618.txt', 'pos/cv227_24215.txt', 'pos/cv228_5806.txt', 'pos/cv229_13611.txt', 'pos/cv230_7428.txt', 'pos/cv231_10425.txt', 'pos/cv232_14991.txt', 'pos/cv233_15964.txt', 'pos/cv234_20643.txt', 'pos/cv235_10217.txt', 'pos/cv236_11565.txt', 'pos/cv237_19221.txt', 'pos/cv238_12931.txt', 'pos/cv239_3385.txt', 'pos/cv240_14336.txt', 'pos/cv241_23130.txt', 'pos/cv242_10638.txt', 'pos/cv243_20728.txt', 'pos/cv244_21649.txt', 'pos/cv245_8569.txt', 'pos/cv246_28807.txt', 'pos/cv247_13142.txt', 'pos/cv248_13987.txt', 'pos/cv249_11640.txt', 'pos/cv250_25616.txt', 'pos/cv251_22636.txt', 'pos/cv252_23779.txt', 'pos/cv253_10077.txt', 'pos/cv254_6027.txt', 'pos/cv255_13683.txt', 'pos/cv256_14740.txt', 'pos/cv257_10975.txt', 'pos/cv258_5792.txt', 'pos/cv259_10934.txt', 'pos/cv260_13959.txt', 'pos/cv261_10954.txt', 'pos/cv262_12649.txt', 'pos/cv263_19259.txt', 'pos/cv264_12801.txt', 'pos/cv265_10814.txt', 'pos/cv266_25779.txt', 'pos/cv267_14952.txt', 'pos/cv268_18834.txt', 'pos/cv269_21732.txt', 'pos/cv270_6079.txt', 'pos/cv271_13837.txt', 'pos/cv272_18974.txt', 'pos/cv273_29112.txt', 'pos/cv274_25253.txt', 'pos/cv275_28887.txt', 'pos/cv276_15684.txt', 'pos/cv277_19091.txt', 'pos/cv278_13041.txt', 'pos/cv279_18329.txt', 'pos/cv280_8267.txt', 'pos/cv281_23253.txt', 'pos/cv282_6653.txt', 'pos/cv283_11055.txt', 'pos/cv284_19119.txt', 'pos/cv285_16494.txt', 'pos/cv286_25050.txt', 'pos/cv287_15900.txt', 'pos/cv288_18791.txt', 'pos/cv289_6463.txt', 'pos/cv290_11084.txt', 'pos/cv291_26635.txt', 'pos/cv292_7282.txt', 'pos/cv293_29856.txt', 'pos/cv294_11684.txt', 'pos/cv295_15570.txt', 'pos/cv296_12251.txt', 'pos/cv297_10047.txt', 'pos/cv298_23111.txt', 'pos/cv299_16214.txt', 'pos/cv300_22284.txt', 'pos/cv301_12146.txt', 'pos/cv302_25649.txt', 'pos/cv303_27520.txt', 'pos/cv304_28706.txt', 'pos/cv305_9946.txt', 'pos/cv306_10364.txt', 'pos/cv307_25270.txt', 'pos/cv308_5016.txt', 'pos/cv309_22571.txt', 'pos/cv310_13091.txt', 'pos/cv311_16002.txt', 'pos/cv312_29377.txt', 'pos/cv313_18198.txt', 'pos/cv314_14422.txt', 'pos/cv315_11629.txt', 'pos/cv316_6370.txt', 'pos/cv317_24049.txt', 'pos/cv318_10493.txt', 'pos/cv319_14727.txt', 'pos/cv320_9530.txt', 'pos/cv321_12843.txt', 'pos/cv322_20318.txt', 'pos/cv323_29805.txt', 'pos/cv324_7082.txt', 'pos/cv325_16629.txt', 'pos/cv326_13295.txt', 'pos/cv327_20292.txt', 'pos/cv328_10373.txt', 'pos/cv329_29370.txt', 'pos/cv330_29809.txt', 'pos/cv331_8273.txt', 'pos/cv332_16307.txt', 'pos/cv333_8916.txt', 'pos/cv334_10001.txt', 'pos/cv335_14665.txt', 'pos/cv336_10143.txt', 'pos/cv337_29181.txt', 'pos/cv338_8821.txt', 'pos/cv339_21119.txt', 'pos/cv340_13287.txt', 'pos/cv341_24430.txt', 'pos/cv342_19456.txt', 'pos/cv343_10368.txt', 'pos/cv344_5312.txt', 'pos/cv345_9954.txt', 'pos/cv346_18168.txt', 'pos/cv347_13194.txt', 'pos/cv348_18176.txt', 'pos/cv349_13507.txt', 'pos/cv350_20670.txt', 'pos/cv351_15458.txt', 'pos/cv352_5524.txt', 'pos/cv353_18159.txt', 'pos/cv354_8132.txt', 'pos/cv355_16413.txt', 'pos/cv356_25163.txt', 'pos/cv357_13156.txt', 'pos/cv358_10691.txt', 'pos/cv359_6647.txt', 'pos/cv360_8398.txt', 'pos/cv361_28944.txt', 'pos/cv362_15341.txt', 'pos/cv363_29332.txt', 'pos/cv364_12901.txt', 'pos/cv365_11576.txt', 'pos/cv366_10221.txt', 'pos/cv367_22792.txt', 'pos/cv368_10466.txt', 'pos/cv369_12886.txt', 'pos/cv370_5221.txt', 'pos/cv371_7630.txt', 'pos/cv372_6552.txt', 'pos/cv373_20404.txt', 'pos/cv374_25436.txt', 'pos/cv375_9929.txt', 'pos/cv376_19435.txt', 'pos/cv377_7946.txt', 'pos/cv378_20629.txt', 'pos/cv379_21963.txt', 'pos/cv380_7574.txt', 'pos/cv381_20172.txt', 'pos/cv382_7897.txt', 'pos/cv383_13116.txt', 'pos/cv384_17140.txt', 'pos/cv385_29741.txt', 'pos/cv386_10080.txt', 'pos/cv387_11507.txt', 'pos/cv388_12009.txt', 'pos/cv389_9369.txt', 'pos/cv390_11345.txt', 'pos/cv391_10802.txt', 'pos/cv392_11458.txt', 'pos/cv393_29327.txt', 'pos/cv394_5137.txt', 'pos/cv395_10849.txt', 'pos/cv396_17989.txt', 'pos/cv397_29023.txt', 'pos/cv398_15537.txt', 'pos/cv399_2877.txt', 'pos/cv400_19220.txt', 'pos/cv401_12605.txt', 'pos/cv402_14425.txt', 'pos/cv403_6621.txt', 'pos/cv404_20315.txt', 'pos/cv405_20399.txt', 'pos/cv406_21020.txt', 'pos/cv407_22637.txt', 'pos/cv408_5297.txt', 'pos/cv409_29786.txt', 'pos/cv410_24266.txt', 'pos/cv411_15007.txt', 'pos/cv412_24095.txt', 'pos/cv413_7398.txt', 'pos/cv414_10518.txt', 'pos/cv415_22517.txt', 'pos/cv416_11136.txt', 'pos/cv417_13115.txt', 'pos/cv418_14774.txt', 'pos/cv419_13394.txt', 'pos/cv420_28795.txt', 'pos/cv421_9709.txt', 'pos/cv422_9381.txt', 'pos/cv423_11155.txt', 'pos/cv424_8831.txt', 'pos/cv425_8250.txt', 'pos/cv426_10421.txt', 'pos/cv427_10825.txt', 'pos/cv428_11347.txt', 'pos/cv429_7439.txt', 'pos/cv430_17351.txt', 'pos/cv431_7085.txt', 'pos/cv432_14224.txt', 'pos/cv433_10144.txt', 'pos/cv434_5793.txt', 'pos/cv435_23110.txt', 'pos/cv436_19179.txt', 'pos/cv437_22849.txt', 'pos/cv438_8043.txt', 'pos/cv439_15970.txt', 'pos/cv440_15243.txt', 'pos/cv441_13711.txt', 'pos/cv442_13846.txt', 'pos/cv443_21118.txt', 'pos/cv444_9974.txt', 'pos/cv445_25882.txt', 'pos/cv446_11353.txt', 'pos/cv447_27332.txt', 'pos/cv448_14695.txt', 'pos/cv449_8785.txt', 'pos/cv450_7890.txt', 'pos/cv451_10690.txt', 'pos/cv452_5088.txt', 'pos/cv453_10379.txt', 'pos/cv454_2053.txt', 'pos/cv455_29000.txt', 'pos/cv456_18985.txt', 'pos/cv457_18453.txt', 'pos/cv458_8604.txt', 'pos/cv459_20319.txt', 'pos/cv460_10842.txt', 'pos/cv461_19600.txt', 'pos/cv462_19350.txt', 'pos/cv463_10343.txt', 'pos/cv464_15650.txt', 'pos/cv465_22431.txt', 'pos/cv466_18722.txt', 'pos/cv467_25773.txt', 'pos/cv468_15228.txt', 'pos/cv469_20630.txt', 'pos/cv470_15952.txt', 'pos/cv471_16858.txt', 'pos/cv472_29280.txt', 'pos/cv473_7367.txt', 'pos/cv474_10209.txt', 'pos/cv475_21692.txt', 'pos/cv476_16856.txt', 'pos/cv477_22479.txt', 'pos/cv478_14309.txt', 'pos/cv479_5649.txt', 'pos/cv480_19817.txt', 'pos/cv481_7436.txt', 'pos/cv482_10580.txt', 'pos/cv483_16378.txt', 'pos/cv484_25054.txt', 'pos/cv485_26649.txt', 'pos/cv486_9799.txt', 'pos/cv487_10446.txt', 'pos/cv488_19856.txt', 'pos/cv489_17906.txt', 'pos/cv490_17872.txt', 'pos/cv491_12145.txt', 'pos/cv492_18271.txt', 'pos/cv493_12839.txt', 'pos/cv494_17389.txt', 'pos/cv495_14518.txt', 'pos/cv496_10530.txt', 'pos/cv497_26980.txt', 'pos/cv498_8832.txt', 'pos/cv499_10658.txt', 'pos/cv500_10251.txt', 'pos/cv501_11657.txt', 'pos/cv502_10406.txt', 'pos/cv503_10558.txt', 'pos/cv504_29243.txt', 'pos/cv505_12090.txt', 'pos/cv506_15956.txt', 'pos/cv507_9220.txt', 'pos/cv508_16006.txt', 'pos/cv509_15888.txt', 'pos/cv510_23360.txt', 'pos/cv511_10132.txt', 'pos/cv512_15965.txt', 'pos/cv513_6923.txt', 'pos/cv514_11187.txt', 'pos/cv515_17069.txt', 'pos/cv516_11172.txt', 'pos/cv517_19219.txt', 'pos/cv518_13331.txt', 'pos/cv519_14661.txt', 'pos/cv520_12295.txt', 'pos/cv521_15828.txt', 'pos/cv522_5583.txt', 'pos/cv523_16615.txt', 'pos/cv524_23627.txt', 'pos/cv525_16122.txt', 'pos/cv526_12083.txt', 'pos/cv527_10123.txt', 'pos/cv528_10822.txt', 'pos/cv529_10420.txt', 'pos/cv530_16212.txt', 'pos/cv531_26486.txt', 'pos/cv532_6522.txt', 'pos/cv533_9821.txt', 'pos/cv534_14083.txt', 'pos/cv535_19728.txt', 'pos/cv536_27134.txt', 'pos/cv537_12370.txt', 'pos/cv538_28667.txt', 'pos/cv539_20347.txt', 'pos/cv540_3421.txt', 'pos/cv541_28835.txt', 'pos/cv542_18980.txt', 'pos/cv543_5045.txt', 'pos/cv544_5108.txt', 'pos/cv545_12014.txt', 'pos/cv546_11767.txt', 'pos/cv547_16324.txt', 'pos/cv548_17731.txt', 'pos/cv549_21443.txt', 'pos/cv550_22211.txt', 'pos/cv551_10565.txt', 'pos/cv552_10016.txt', 'pos/cv553_26915.txt', 'pos/cv554_13151.txt', 'pos/cv555_23922.txt', 'pos/cv556_14808.txt', 'pos/cv557_11449.txt', 'pos/cv558_29507.txt', 'pos/cv559_0050.txt', 'pos/cv560_17175.txt', 'pos/cv561_9201.txt', 'pos/cv562_10359.txt', 'pos/cv563_17257.txt', 'pos/cv564_11110.txt', 'pos/cv565_29572.txt', 'pos/cv566_8581.txt', 'pos/cv567_29611.txt', 'pos/cv568_15638.txt', 'pos/cv569_26381.txt', 'pos/cv570_29082.txt', 'pos/cv571_29366.txt', 'pos/cv572_18657.txt', 'pos/cv573_29525.txt', 'pos/cv574_22156.txt', 'pos/cv575_21150.txt', 'pos/cv576_14094.txt', 'pos/cv577_28549.txt', 'pos/cv578_15094.txt', 'pos/cv579_11605.txt', 'pos/cv580_14064.txt', 'pos/cv581_19381.txt', 'pos/cv582_6559.txt', 'pos/cv583_29692.txt', 'pos/cv584_29722.txt', 'pos/cv585_22496.txt', 'pos/cv586_7543.txt', 'pos/cv587_19162.txt', 'pos/cv588_13008.txt', 'pos/cv589_12064.txt', 'pos/cv590_19290.txt', 'pos/cv591_23640.txt', 'pos/cv592_22315.txt', 'pos/cv593_10987.txt', 'pos/cv594_11039.txt', 'pos/cv595_25335.txt', 'pos/cv596_28311.txt', 'pos/cv597_26360.txt', 'pos/cv598_16452.txt', 'pos/cv599_20988.txt', 'pos/cv600_23878.txt', 'pos/cv601_23453.txt', 'pos/cv602_8300.txt', 'pos/cv603_17694.txt', 'pos/cv604_2230.txt', 'pos/cv605_11800.txt', 'pos/cv606_15985.txt', 'pos/cv607_7717.txt', 'pos/cv608_23231.txt', 'pos/cv609_23877.txt', 'pos/cv610_2287.txt', 'pos/cv611_21120.txt', 'pos/cv612_5461.txt', 'pos/cv613_21796.txt', 'pos/cv614_10626.txt', 'pos/cv615_14182.txt', 'pos/cv616_29319.txt', 'pos/cv617_9322.txt', 'pos/cv618_8974.txt', 'pos/cv619_12462.txt', 'pos/cv620_24265.txt', 'pos/cv621_14368.txt', 'pos/cv622_8147.txt', 'pos/cv623_15356.txt', 'pos/cv624_10744.txt', 'pos/cv625_12440.txt', 'pos/cv626_7410.txt', 'pos/cv627_11620.txt', 'pos/cv628_19325.txt', 'pos/cv629_14909.txt', 'pos/cv630_10057.txt', 'pos/cv631_4967.txt', 'pos/cv632_9610.txt', 'pos/cv633_29837.txt', 'pos/cv634_11101.txt', 'pos/cv635_10022.txt', 'pos/cv636_15279.txt', 'pos/cv637_1250.txt', 'pos/cv638_2953.txt', 'pos/cv639_10308.txt', 'pos/cv640_5378.txt', 'pos/cv641_12349.txt', 'pos/cv642_29867.txt', 'pos/cv643_29349.txt', 'pos/cv644_17154.txt', 'pos/cv645_15668.txt', 'pos/cv646_15065.txt', 'pos/cv647_13691.txt', 'pos/cv648_15792.txt', 'pos/cv649_12735.txt', 'pos/cv650_14340.txt', 'pos/cv651_10492.txt', 'pos/cv652_13972.txt', 'pos/cv653_19583.txt', 'pos/cv654_18246.txt', 'pos/cv655_11154.txt', 'pos/cv656_24201.txt', 'pos/cv657_24513.txt', 'pos/cv658_10532.txt', 'pos/cv659_19944.txt', 'pos/cv660_21893.txt', 'pos/cv661_2450.txt', 'pos/cv662_13320.txt', 'pos/cv663_13019.txt', 'pos/cv664_4389.txt', 'pos/cv665_29538.txt', 'pos/cv666_18963.txt', 'pos/cv667_18467.txt', 'pos/cv668_17604.txt', 'pos/cv669_22995.txt', 'pos/cv670_25826.txt', 'pos/cv671_5054.txt', 'pos/cv672_28083.txt', 'pos/cv673_24714.txt', 'pos/cv674_10732.txt', 'pos/cv675_21588.txt', 'pos/cv676_21090.txt', 'pos/cv677_17715.txt', 'pos/cv678_13419.txt', 'pos/cv679_28559.txt', 'pos/cv680_10160.txt', 'pos/cv681_9692.txt', 'pos/cv682_16139.txt', 'pos/cv683_12167.txt', 'pos/cv684_11798.txt', 'pos/cv685_5947.txt', 'pos/cv686_13900.txt', 'pos/cv687_21100.txt', 'pos/cv688_7368.txt', 'pos/cv689_12587.txt', 'pos/cv690_5619.txt', 'pos/cv691_5043.txt', 'pos/cv692_15451.txt', 'pos/cv693_18063.txt', 'pos/cv694_4876.txt', 'pos/cv695_21108.txt', 'pos/cv696_29740.txt', 'pos/cv697_11162.txt', 'pos/cv698_15253.txt', 'pos/cv699_7223.txt', 'pos/cv700_21947.txt', 'pos/cv701_14252.txt', 'pos/cv702_11500.txt', 'pos/cv703_16143.txt', 'pos/cv704_15969.txt', 'pos/cv705_11059.txt', 'pos/cv706_24716.txt', 'pos/cv707_10678.txt', 'pos/cv708_28729.txt', 'pos/cv709_10529.txt', 'pos/cv710_22577.txt', 'pos/cv711_11665.txt', 'pos/cv712_22920.txt', 'pos/cv713_29155.txt', 'pos/cv714_18502.txt', 'pos/cv715_18179.txt', 'pos/cv716_10514.txt', 'pos/cv717_15953.txt', 'pos/cv718_11434.txt', 'pos/cv719_5713.txt', 'pos/cv720_5389.txt', 'pos/cv721_29121.txt', 'pos/cv722_7110.txt', 'pos/cv723_8648.txt', 'pos/cv724_13681.txt', 'pos/cv725_10103.txt', 'pos/cv726_4719.txt', 'pos/cv727_4978.txt', 'pos/cv728_16133.txt', 'pos/cv729_10154.txt', 'pos/cv730_10279.txt', 'pos/cv731_4136.txt', 'pos/cv732_12245.txt', 'pos/cv733_9839.txt', 'pos/cv734_21568.txt', 'pos/cv735_18801.txt', 'pos/cv736_23670.txt', 'pos/cv737_28907.txt', 'pos/cv738_10116.txt', 'pos/cv739_11209.txt', 'pos/cv740_12445.txt', 'pos/cv741_11890.txt', 'pos/cv742_7751.txt', 'pos/cv743_15449.txt', 'pos/cv744_10038.txt', 'pos/cv745_12773.txt', 'pos/cv746_10147.txt', 'pos/cv747_16556.txt', 'pos/cv748_12786.txt', 'pos/cv749_17765.txt', 'pos/cv750_10180.txt', 'pos/cv751_15719.txt', 'pos/cv752_24155.txt', 'pos/cv753_10875.txt', 'pos/cv754_7216.txt', 'pos/cv755_23616.txt', 'pos/cv756_22540.txt', 'pos/cv757_10189.txt', 'pos/cv758_9671.txt', 'pos/cv759_13522.txt', 'pos/cv760_8597.txt', 'pos/cv761_12620.txt', 'pos/cv762_13927.txt', 'pos/cv763_14729.txt', 'pos/cv764_11739.txt', 'pos/cv765_19037.txt', 'pos/cv766_7540.txt', 'pos/cv767_14062.txt', 'pos/cv768_11751.txt', 'pos/cv769_8123.txt', 'pos/cv770_10451.txt', 'pos/cv771_28665.txt', 'pos/cv772_12119.txt', 'pos/cv773_18817.txt', 'pos/cv774_13845.txt', 'pos/cv775_16237.txt', 'pos/cv776_20529.txt', 'pos/cv777_10094.txt', 'pos/cv778_17330.txt', 'pos/cv779_17881.txt', 'pos/cv780_7984.txt', 'pos/cv781_5262.txt', 'pos/cv782_19526.txt', 'pos/cv783_13227.txt', 'pos/cv784_14394.txt', 'pos/cv785_22600.txt', 'pos/cv786_22497.txt', 'pos/cv787_13743.txt', 'pos/cv788_25272.txt', 'pos/cv789_12136.txt', 'pos/cv790_14600.txt', 'pos/cv791_16302.txt', 'pos/cv792_3832.txt', 'pos/cv793_13650.txt', 'pos/cv794_15868.txt', 'pos/cv795_10122.txt', 'pos/cv796_15782.txt', 'pos/cv797_6957.txt', 'pos/cv798_23531.txt', 'pos/cv799_18543.txt', 'pos/cv800_12368.txt', 'pos/cv801_25228.txt', 'pos/cv802_28664.txt', 'pos/cv803_8207.txt', 'pos/cv804_10862.txt', 'pos/cv805_19601.txt', 'pos/cv806_8842.txt', 'pos/cv807_21740.txt', 'pos/cv808_12635.txt', 'pos/cv809_5009.txt', 'pos/cv810_12458.txt', 'pos/cv811_21386.txt', 'pos/cv812_17924.txt', 'pos/cv813_6534.txt', 'pos/cv814_18975.txt', 'pos/cv815_22456.txt', 'pos/cv816_13655.txt', 'pos/cv817_4041.txt', 'pos/cv818_10211.txt', 'pos/cv819_9364.txt', 'pos/cv820_22892.txt', 'pos/cv821_29364.txt', 'pos/cv822_20049.txt', 'pos/cv823_15569.txt', 'pos/cv824_8838.txt', 'pos/cv825_5063.txt', 'pos/cv826_11834.txt', 'pos/cv827_18331.txt', 'pos/cv828_19831.txt', 'pos/cv829_20289.txt', 'pos/cv830_6014.txt', 'pos/cv831_14689.txt', 'pos/cv832_23275.txt', 'pos/cv833_11053.txt', 'pos/cv834_22195.txt', 'pos/cv835_19159.txt', 'pos/cv836_12968.txt', 'pos/cv837_27325.txt', 'pos/cv838_24728.txt', 'pos/cv839_21467.txt', 'pos/cv840_16321.txt', 'pos/cv841_3967.txt', 'pos/cv842_5866.txt', 'pos/cv843_15544.txt', 'pos/cv844_12690.txt', 'pos/cv845_14290.txt', 'pos/cv846_29497.txt', 'pos/cv847_1941.txt', 'pos/cv848_10036.txt', 'pos/cv849_15729.txt', 'pos/cv850_16466.txt', 'pos/cv851_20469.txt', 'pos/cv852_27523.txt', 'pos/cv853_29233.txt', 'pos/cv854_17740.txt', 'pos/cv855_20661.txt', 'pos/cv856_29013.txt', 'pos/cv857_15958.txt', 'pos/cv858_18819.txt', 'pos/cv859_14107.txt', 'pos/cv860_13853.txt', 'pos/cv861_1198.txt', 'pos/cv862_14324.txt', 'pos/cv863_7424.txt', 'pos/cv864_3416.txt', 'pos/cv865_2895.txt', 'pos/cv866_29691.txt', 'pos/cv867_16661.txt', 'pos/cv868_11948.txt', 'pos/cv869_23611.txt', 'pos/cv870_16348.txt', 'pos/cv871_24888.txt', 'pos/cv872_12591.txt', 'pos/cv873_18636.txt', 'pos/cv874_11236.txt', 'pos/cv875_5754.txt', 'pos/cv876_9390.txt', 'pos/cv877_29274.txt', 'pos/cv878_15694.txt', 'pos/cv879_14903.txt', 'pos/cv880_29800.txt', 'pos/cv881_13254.txt', 'pos/cv882_10026.txt', 'pos/cv883_27751.txt', 'pos/cv884_13632.txt', 'pos/cv885_12318.txt', 'pos/cv886_18177.txt', 'pos/cv887_5126.txt', 'pos/cv888_24435.txt', 'pos/cv889_21430.txt', 'pos/cv890_3977.txt', 'pos/cv891_6385.txt', 'pos/cv892_17576.txt', 'pos/cv893_26269.txt', 'pos/cv894_2068.txt', 'pos/cv895_21022.txt', 'pos/cv896_16071.txt', 'pos/cv897_10837.txt', 'pos/cv898_14187.txt', 'pos/cv899_16014.txt', 'pos/cv900_10331.txt', 'pos/cv901_11017.txt', 'pos/cv902_12256.txt', 'pos/cv903_17822.txt', 'pos/cv904_24353.txt', 'pos/cv905_29114.txt', 'pos/cv906_11491.txt', 'pos/cv907_3541.txt', 'pos/cv908_16009.txt', 'pos/cv909_9960.txt', 'pos/cv910_20488.txt', 'pos/cv911_20260.txt', 'pos/cv912_5674.txt', 'pos/cv913_29252.txt', 'pos/cv914_28742.txt', 'pos/cv915_8841.txt', 'pos/cv916_15467.txt', 'pos/cv917_29715.txt', 'pos/cv918_2693.txt', 'pos/cv919_16380.txt', 'pos/cv920_29622.txt', 'pos/cv921_12747.txt', 'pos/cv922_10073.txt', 'pos/cv923_11051.txt', 'pos/cv924_29540.txt', 'pos/cv925_8969.txt', 'pos/cv926_17059.txt', 'pos/cv927_10681.txt', 'pos/cv928_9168.txt', 'pos/cv929_16908.txt', 'pos/cv930_13475.txt', 'pos/cv931_17563.txt', 'pos/cv932_13401.txt', 'pos/cv933_23776.txt', 'pos/cv934_19027.txt', 'pos/cv935_23841.txt', 'pos/cv936_15954.txt', 'pos/cv937_9811.txt', 'pos/cv938_10220.txt', 'pos/cv939_10583.txt', 'pos/cv940_17705.txt', 'pos/cv941_10246.txt', 'pos/cv942_17082.txt', 'pos/cv943_22488.txt', 'pos/cv944_13521.txt', 'pos/cv945_12160.txt', 'pos/cv946_18658.txt', 'pos/cv947_10601.txt', 'pos/cv948_24606.txt', 'pos/cv949_20112.txt', 'pos/cv950_12350.txt', 'pos/cv951_10926.txt', 'pos/cv952_25240.txt', 'pos/cv953_6836.txt', 'pos/cv954_18628.txt', 'pos/cv955_25001.txt', 'pos/cv956_11609.txt', 'pos/cv957_8737.txt', 'pos/cv958_12162.txt', 'pos/cv959_14611.txt', 'pos/cv960_29007.txt', 'pos/cv961_5682.txt', 'pos/cv962_9803.txt', 'pos/cv963_6895.txt', 'pos/cv964_6021.txt', 'pos/cv965_26071.txt', 'pos/cv966_28832.txt', 'pos/cv967_5788.txt', 'pos/cv968_24218.txt', 'pos/cv969_13250.txt', 'pos/cv970_18450.txt', 'pos/cv971_10874.txt', 'pos/cv972_26417.txt', 'pos/cv973_10066.txt', 'pos/cv974_22941.txt', 'pos/cv975_10981.txt', 'pos/cv976_10267.txt', 'pos/cv977_4938.txt', 'pos/cv978_20929.txt', 'pos/cv979_18921.txt', 'pos/cv980_10953.txt', 'pos/cv981_14989.txt', 'pos/cv982_21103.txt', 'pos/cv983_22928.txt', 'pos/cv984_12767.txt', 'pos/cv985_6359.txt', 'pos/cv986_13527.txt', 'pos/cv987_6965.txt', 'pos/cv988_18740.txt', 'pos/cv989_15824.txt', 'pos/cv990_11591.txt', 'pos/cv991_18645.txt', 'pos/cv992_11962.txt', 'pos/cv993_29737.txt', 'pos/cv994_12270.txt', 'pos/cv995_21821.txt', 'pos/cv996_11592.txt', 'pos/cv997_5046.txt', 'pos/cv998_14111.txt', 'pos/cv999_13106.txt']\n"
     ]
    }
   ],
   "source": [
    "print(len(movie_reviews.fileids('pos')))\n",
    "print(' ')\n",
    "print(movie_reviews.fileids('pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_rev = movie_reviews.fileids('neg')\n",
    "len(neg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'wish', 'i', 'could', 'say', 'that', 'there', ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = nltk.corpus.movie_reviews.words('pos/cv988_18740.txt')\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev in neg_rev:\n",
    "    rev_text_neg = rev = nltk.corpus.movie_reviews.words(rev)\n",
    "    review_one_string = \" \".join(rev_text_neg)\n",
    "    review_one_string = review_one_string.replace(' ,', ',')\n",
    "    review_one_string = review_one_string.replace(' .', '.')\n",
    "    review_one_string = review_one_string.replace(\"\\' \" , \"'\")\n",
    "    review_one_string = review_one_string.replace(\" \\'\" , \"'\")\n",
    "    rev_list.append(review_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev = movie_reviews.fileids('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev_pos in pos_rev:\n",
    "    rev_text_pos = rev = nltk.corpus.movie_reviews.words(rev_pos)\n",
    "    review_one_string = \" \".join(rev_text_neg)\n",
    "    review_one_string = review_one_string.replace(' ,', ',')\n",
    "    review_one_string = review_one_string.replace(' .', '.')\n",
    "    review_one_string = review_one_string.replace(\"\\' \" , \"'\")\n",
    "    review_one_string = review_one_string.replace(\" \\'\" , \"'\")\n",
    "    rev_list.append(review_one_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_targets = np.zeros((1000), dtype = np.int)\n",
    "pos_targets = np.ones((1000), dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for neg_tar in neg_targets:\n",
    "    target_list.append(neg_tar)\n",
    "    \n",
    "for pos_tar in pos_targets:\n",
    "    target_list.append(pos_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
